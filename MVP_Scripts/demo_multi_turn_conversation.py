"""
MVP Alpha æ¼”ç¤ºè„šæœ¬ï¼šå¤šè½®å¯¹è¯åœºæ™¯

æ¼”ç¤ºå®Œæ•´çš„å¤šè½®å¯¹è¯æµç¨‹ï¼Œå±•ç¤ºï¼š
- SessionManager çš„ä¸Šä¸‹æ–‡ç®¡ç†
- AssessmentRepo çš„æŒä¹…åŒ–
- ConversationEngine çš„å®Œæ•´æµç¨‹
- å¤šè½®å¯¹è¯ä¸­çš„ä¸Šä¸‹æ–‡ä¼ é€’
"""

import asyncio
import sys
from pathlib import Path
import httpx

# è®¾ç½® UTF-8 ç¼–ç ï¼ˆWindows å…¼å®¹ï¼‰
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.conversation.engine import ConversationEngine, ConversationRequest
from src.conversation.session_manager import SessionManager
from src.services.ollama_service import OllamaService
from src.core.config import settings


async def check_ollama_connection() -> bool:
    """æ£€æŸ¥ Ollama æœåŠ¡æ˜¯å¦å¯ç”¨"""
    try:
        async with httpx.AsyncClient(timeout=5.0) as client:
            response = await client.get(f"{settings.OLLAMA_URL}/api/tags")
            if response.status_code == 200:
                models = response.json().get("models", [])
                model_names = [m["name"] for m in models]
                if settings.MODEL_NAME in model_names:
                    return True
            return False
    except Exception:
        return False


async def demo_multi_turn_conversation():
    """æ¼”ç¤ºå¤šè½®å¯¹è¯åœºæ™¯"""
    
    print("=" * 80)
    print("MVP Alpha æ¼”ç¤ºï¼šå¤šè½®å¯¹è¯åœºæ™¯")
    print("=" * 80)
    print("\næœ¬æ¼”ç¤ºå±•ç¤ºå®Œæ•´çš„å¤šè½®å¯¹è¯æµç¨‹ï¼š")
    print("  - SessionManager çš„ä¸Šä¸‹æ–‡ç®¡ç†")
    print("  - AssessmentRepo çš„æŒä¹…åŒ–")
    print("  - ConversationEngine çš„å®Œæ•´æµç¨‹")
    print("  - å¤šè½®å¯¹è¯ä¸­çš„ä¸Šä¸‹æ–‡ä¼ é€’")
    print("=" * 80)
    
    # æ£€æŸ¥ Ollama
    ollama_available = await check_ollama_connection()
    if ollama_available:
        print(f"\n[OK] Ollama æœåŠ¡å¯ç”¨")
    else:
        print(f"\n[WARN] Ollama æœåŠ¡ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨å›é€€å“åº”")
    
    # åˆå§‹åŒ–æœåŠ¡
    llm_service = OllamaService()
    if ollama_available:
        try:
            await llm_service.load_model()
        except Exception:
            pass
    
    engine = ConversationEngine(llm_service)
    user_id = "demo_user_multi_turn_001"
    
    # æ¸…ç©ºä¼šè¯
    SessionManager.clear_session(user_id)
    
    # ç¬¬ä¸€è½®ï¼šåˆæ¬¡æ¥è§¦ï¼ˆGAD-7 é»˜è®¤ï¼‰
    print("\n" + "=" * 80)
    print("[ç¬¬ 1 è½®] åˆæ¬¡æ¥è§¦ï¼ˆGAD-7 é»˜è®¤è¯„ä¼°ï¼‰")
    print("=" * 80)
    
    request1 = ConversationRequest(
        user_id=user_id,
        scale="gad7",
        responses=["0", "1", "1", "0", "1", "0", "1"],
        user_message="ä½ å¥½ï¼Œæˆ‘æƒ³äº†è§£ä¸€ä¸‹æˆ‘çš„ç„¦è™‘æƒ…å†µã€‚"
    )
    
    result1 = await engine.run_pipeline(request1)
    
    print(f"\nğŸ“Š è¯„ä¼°ç»“æœ:")
    print(f"  é‡è¡¨: {result1.assessment.get('scale')}")
    print(f"  ä¸¥é‡åº¦: {result1.assessment.get('severity_level')}")
    print(f"  æ€»åˆ†: {result1.assessment.get('total_score')}")
    print(f"  è·¯ç”±: {result1.decision.get('route')}")
    
    if result1.context_tail:
        print(f"\nğŸ“ ä¼šè¯ä¸Šä¸‹æ–‡ï¼ˆ{len(result1.context_tail)} è½®ï¼‰:")
        for turn in result1.context_tail:
            print(f"  [{turn.get('role')}] {turn.get('text')[:60]}...")
    
    # ç­‰å¾…ç”¨æˆ·å“åº”ï¼ˆæ¨¡æ‹Ÿï¼‰
    print("\n[INFO] ç­‰å¾…ç”¨æˆ·å“åº”...")
    await asyncio.sleep(1)
    
    # ç¬¬äºŒè½®ï¼šç»§ç»­å¯¹è¯
    print("\n" + "=" * 80)
    print("[ç¬¬ 2 è½®] ç»§ç»­å¯¹è¯ï¼ˆä½¿ç”¨ä¼šè¯ä¸Šä¸‹æ–‡ï¼‰")
    print("=" * 80)
    
    request2 = ConversationRequest(
        user_id=user_id,
        scale="phq9",
        responses=["1", "1", "2", "1", "1", "1", "1", "1", "0"],
        user_message="æˆ‘è¿˜æƒ³åšä¸€ä¸ªæŠ‘éƒè¯„ä¼°ã€‚"
    )
    
    result2 = await engine.run_pipeline(request2)
    
    print(f"\nğŸ“Š è¯„ä¼°ç»“æœ:")
    print(f"  é‡è¡¨: {result2.assessment.get('scale')}")
    print(f"  ä¸¥é‡åº¦: {result2.assessment.get('severity_level')}")
    print(f"  æ€»åˆ†: {result2.assessment.get('total_score')}")
    print(f"  è·¯ç”±: {result2.decision.get('route')}")
    
    if result2.context_tail:
        print(f"\nğŸ“ ä¼šè¯ä¸Šä¸‹æ–‡ï¼ˆ{len(result2.context_tail)} è½®ï¼‰:")
        print(f"  [æ³¨æ„] ä¸Šä¸‹æ–‡åŒ…å«äº†ç¬¬ 1 è½®å’Œç¬¬ 2 è½®çš„å¯¹è¯")
        for turn in result2.context_tail:
            print(f"  [{turn.get('role')}] {turn.get('text')[:60]}...")
    
    # ç¬¬ä¸‰è½®ï¼šå†æ¬¡å¯¹è¯
    print("\n" + "=" * 80)
    print("[ç¬¬ 3 è½®] å†æ¬¡å¯¹è¯ï¼ˆä¸Šä¸‹æ–‡è‡ªåŠ¨ä¿®å‰ªï¼‰")
    print("=" * 80)
    
    request3 = ConversationRequest(
        user_id=user_id,
        scale="gad7",
        responses=["1", "2", "1", "1", "2", "1", "1"],
        user_message="æˆ‘çš„ç„¦è™‘æƒ…å†µæœ‰æ”¹å–„å—ï¼Ÿ"
    )
    
    result3 = await engine.run_pipeline(request3)
    
    print(f"\nğŸ“Š è¯„ä¼°ç»“æœ:")
    print(f"  é‡è¡¨: {result3.assessment.get('scale')}")
    print(f"  ä¸¥é‡åº¦: {result3.assessment.get('severity_level')}")
    print(f"  æ€»åˆ†: {result3.assessment.get('total_score')}")
    print(f"  è·¯ç”±: {result3.decision.get('route')}")
    
    if result3.context_tail:
        print(f"\nğŸ“ ä¼šè¯ä¸Šä¸‹æ–‡ï¼ˆ{len(result3.context_tail)} è½®ï¼‰:")
        print(f"  [æ³¨æ„] ç³»ç»Ÿè‡ªåŠ¨ä¿®å‰ªåˆ°æœ€è¿‘ 6 è½®")
        for turn in result3.context_tail:
            print(f"  [{turn.get('role')}] {turn.get('text')[:60]}...")
    
    # æ£€æŸ¥å†å²è®°å½•
    print("\n" + "=" * 80)
    print("[æ£€æŸ¥] è¯„ä¼°å†å²è®°å½•")
    print("=" * 80)
    
    history = await engine.repo.history(user_id, limit=10)
    print(f"\n[OK] ç”¨æˆ· {user_id} çš„è¯„ä¼°å†å²ï¼ˆ{len(history)} æ¡è®°å½•ï¼‰:")
    for i, record in enumerate(history, 1):
        print(f"\n  è®°å½• {i}:")
        print(f"    æ—¶é—´: {record.get('ts')}")
        print(f"    é‡è¡¨: {record.get('scale')}")
        print(f"    åˆ†æ•°: {record.get('score')}")
        print(f"    ä¸¥é‡åº¦: {record.get('severity')}")
        print(f"    è·¯ç”±: {record.get('route')}")
    
    # æ€»ç»“
    print("\n" + "=" * 80)
    print("æ¼”ç¤ºæ€»ç»“")
    print("=" * 80)
    print("âœ… å¤šè½®å¯¹è¯åœºæ™¯æ¼”ç¤ºå®Œæˆï¼")
    print("\næ ¸å¿ƒåŠŸèƒ½éªŒè¯ï¼š")
    print("  âœ… SessionManager ç®¡ç†å¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡")
    print("  âœ… AssessmentRepo æŒä¹…åŒ–æ‰€æœ‰è¯„ä¼°è®°å½•")
    print("  âœ… ConversationEngine åœ¨æ¯è½®ä¸­ä½¿ç”¨ä¸Šä¸‹æ–‡")
    print("  âœ… ä¸Šä¸‹æ–‡è‡ªåŠ¨ä¿®å‰ªåˆ°æœ€è¿‘ 6 è½®")
    print("  âœ… å†å²è®°å½•å®Œæ•´ä¿å­˜")
    print("=" * 80)


if __name__ == "__main__":
    try:
        asyncio.run(demo_multi_turn_conversation())
    except KeyboardInterrupt:
        print("\n\n[INFO] æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\n\n[ERROR] å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

