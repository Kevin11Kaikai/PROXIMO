# æ•´ä½“é›†æˆæµ‹è¯•æ–‡æ¡£

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº”å±‚æ¶æ„çš„æ•´ä½“é›†æˆæµ‹è¯•ï¼ŒåŒ…æ‹¬7ä¸ªæµ‹è¯•åœºæ™¯çš„ç›®çš„ã€æµç¨‹å’Œå…³é”®ä»£ç å®ç°ã€‚

## ğŸ“‹ æµ‹è¯•æ¦‚è§ˆ

| æµ‹è¯•è„šæœ¬ | æµ‹è¯•ç±»å‹ | ä¸»è¦éªŒè¯ç‚¹ |
|---------|---------|-----------|
| `test_low_risk_scenario.py` | åœºæ™¯æµ‹è¯• | Low Risk å®Œæ•´æµç¨‹ |
| `test_medium_risk_scenario.py` | åœºæ™¯æµ‹è¯• | Medium Risk å®Œæ•´æµç¨‹ï¼ˆå«æŠ—æ‹’å¤„ç†ï¼‰ |
| `test_high_risk_scenario.py` | åœºæ™¯æµ‹è¯• | High Risk å®Œæ•´æµç¨‹ï¼ˆå›ºå®šè„šæœ¬ï¼‰ |
| `test_route_transitions.py` | åŠŸèƒ½æµ‹è¯• | è·¯ç”±è½¬æ¢é€»è¾‘ï¼ˆå‡çº§/ä¸é™çº§ï¼‰ |
| `test_boundary_cases.py` | è¾¹ç•Œæµ‹è¯• | é˜ˆå€¼è¾¹ç•Œã€è§¦å‘æ—¶æœºã€é—®å·åˆ†æ•° |
| `test_error_recovery.py` | å®¹é”™æµ‹è¯• | æœåŠ¡ä¸å¯ç”¨æ—¶çš„é™çº§å¤„ç† |
| `test_safety_monitoring.py` | å®‰å…¨æµ‹è¯• | å›ºå®šè„šæœ¬å®Œæ•´æ€§ã€å±æœºæ£€æµ‹ |

---

## 1. Low Risk åœºæ™¯æµ‹è¯•

### æµ‹è¯•ç›®çš„
éªŒè¯ Low Risk ç”¨æˆ·çš„å®Œæ•´å¯¹è¯æµç¨‹ï¼ŒåŒ…æ‹¬ï¼š
- åˆå§‹å¯¹è¯å’Œ PsyGUARD è¯„åˆ†
- GAD-7 é—®å·è§¦å‘å’Œè¯„ä¼°
- è·¯ç”±å†³ç­–ï¼ˆLow Riskï¼‰
- åº”å¯¹ç­–ç•¥æä¾›
- Goodbye æ£€æµ‹
- åé¦ˆæ”¶é›†

### æµ‹è¯•æµç¨‹

```python
async def test_low_risk_complete_flow():
    """Test complete Low Risk flow."""
    # Step 1: Initial conversation
    user_message_1 = "I've been feeling a bit stressed lately with school."
    psyguard_result_1 = await psyguard_service.score(user_message_1)
    
    # Step 2: Trigger GAD-7 assessment
    gad7_responses = ["0", "1", "0", "1", "0", "1", "0"]  # Total: 3 (Low Risk)
    gad7_result = await questionnaire_service.assess("gad7", gad7_responses, user_id)
    
    # Step 3: Route decision
    routing_result = router.decide_from_questionnaires(
        phq9_result={"total_score": 0.0, "parsed_scores": [0] * 9},
        gad7_result=gad7_result,
        chat_risk_score=psyguard_score_1
    )
    assert routing_result.route == "low"
    
    # Step 4: Continue conversation with coping strategies
    user_message_2 = "What can I do to feel better?"
    result_2 = await pipeline.process_message(
        user_id=user_id,
        user_message=user_message_2,
        control_context=context
    )
    
    # Step 5: User says goodbye
    user_message_3 = "Thanks for your help! Goodbye."
    result_3 = await pipeline.process_message(...)
    
    # Step 6: Collect feedback
    feedback = history_service.collect_feedback(
        user_id=user_id,
        conversation_id="conv_low_risk",
        route="low",
        satisfaction=4,
        acceptance="accepted",
        follow_up_behavior="none"
    )
```

### å…³é”®éªŒè¯ç‚¹

1. **PsyGUARD è¯„åˆ†**ï¼šæ£€æµ‹ä½é£é™©ä¿¡å·
   ```python
   psyguard_score_1 = psyguard_result_1.get("risk_score", 0.0)
   # Expected: Low risk score (< 0.70)
   ```

2. **é—®å·è¯„ä¼°**ï¼šGAD-7 æ€»åˆ† 3ï¼Œæ˜ å°„åˆ° Low Risk
   ```python
   gad7_result = await questionnaire_service.assess("gad7", gad7_responses, user_id)
   # Expected: total_score = 3.0, severity_level = "minimal"
   ```

3. **è·¯ç”±å†³ç­–**ï¼šåŸºäºé—®å·ç»“æœåˆ†é… Low Risk
   ```python
   routing_result = router.decide_from_questionnaires(...)
   # Expected: route = "low", rigid_score â‰ˆ 0.15
   ```

4. **Goodbye æ£€æµ‹**ï¼šè¯†åˆ«ç”¨æˆ·å‘Šåˆ«
   ```python
   is_goodbye = low_agent.is_goodbye(user_message_3)
   # Expected: True
   ```

---

## 2. Medium Risk åœºæ™¯æµ‹è¯•

### æµ‹è¯•ç›®çš„
éªŒè¯ Medium Risk ç”¨æˆ·çš„å®Œæ•´æµç¨‹ï¼Œç‰¹åˆ«å…³æ³¨ï¼š
- Peer Group å»ºè®®
- ç”¨æˆ·æŠ—æ‹’æ£€æµ‹å’Œå¤„ç†
- çŠ¶æ€æœºè½¬æ¢ï¼ˆdetecting_resistance â†’ handling_resistance â†’ acceptedï¼‰
- æœ€å¤§è¯´æœè½®æ¬¡é™åˆ¶ï¼ˆ5 è½®ï¼‰

### æµ‹è¯•æµç¨‹

```python
async def test_medium_risk_complete_flow():
    """Test complete Medium Risk flow."""
    # Step 1-3: Initial conversation, GAD-7 assessment, route decision
    # (Similar to Low Risk, but with higher scores)
    
    # Step 4: Suggest peer group
    user_message_2 = "I don't know what to do about my anxiety."
    result_2 = await pipeline.process_message(...)
    # Expected: state = "detecting_resistance"
    
    # Step 5: User shows resistance
    user_message_3 = "I don't want to share my personal information with strangers."
    result_3 = await pipeline.process_message(...)
    # Expected: resistance_type = "privacy", resistance_count = 1
    
    # Step 6: ChatBot addresses resistance (multiple turns)
    for turn in range(2):
        user_message_resistance = f"I'm still not sure about joining. (turn {turn + 1})"
        result_resistance = await pipeline.process_message(...)
        # Expected: resistance_count increases, state = "handling_resistance"
    
    # Step 7: User accepts
    user_message_4 = "Okay, I'll give it a try. I'd like to join the peer group."
    result_4 = await pipeline.process_message(...)
    # Expected: state = "accepted", peer_group_accepted = True
```

### å…³é”®éªŒè¯ç‚¹

1. **æŠ—æ‹’æ£€æµ‹**ï¼šè¯†åˆ«ç”¨æˆ·æŠ—æ‹’ç±»å‹ï¼ˆprivacy, time, stigma, doubtï¼‰
   ```python
   # From MediumRiskAgent
   RESISTANCE_KEYWORDS = ["privacy", "time", "stigma", "doubt"]
   
   def _detect_resistance(self, user_message: str) -> Optional[str]:
       """Detect resistance type from user message."""
       user_lower = user_message.lower()
       for keyword in self.RESISTANCE_KEYWORDS:
           if keyword in user_lower:
               return keyword
       return None
   ```

2. **çŠ¶æ€æœºè½¬æ¢**ï¼š
   ```python
   # State transitions in MediumRiskAgent
   if state == "detecting_resistance":
       if resistance_detected:
           state = "handling_resistance"
   elif state == "handling_resistance":
       if resistance_count >= MAX_PERSUASION_TURNS:
           state = "rejected"
       elif user_accepts:
           state = "accepted"
   ```

3. **æœ€å¤§è¯´æœè½®æ¬¡**ï¼šæœ€å¤š 5 è½®è¯´æœå°è¯•
   ```python
   MAX_PERSUASION_TURNS = 5
   
   if resistance_count >= MAX_PERSUASION_TURNS:
       # Provide self-help resources and end persuasion
       state = "rejected"
   ```

---

## 3. High Risk åœºæ™¯æµ‹è¯•

### æµ‹è¯•ç›®çš„
éªŒè¯ High Risk åœºæ™¯çš„å±æœºå¤„ç†æµç¨‹ï¼š
- è‡ªæ€è¯­è¨€æ£€æµ‹
- ç«‹å³é«˜é£é™©åˆ†é…ï¼ˆèŠå¤©å†…å®¹ä¼˜å…ˆçº§ï¼‰
- å›ºå®šå®‰å…¨è„šæœ¬æ‰§è¡Œ
- Safety Layer ç›‘æ§ï¼ˆè„šæœ¬ä¸è¢«ä¿®æ”¹ï¼‰
- ç‰¹æ®Šåé¦ˆæ”¶é›†ï¼ˆä»… sought_helpï¼‰

### æµ‹è¯•æµç¨‹

```python
async def test_high_risk_complete_flow():
    """Test complete High Risk flow."""
    # Step 1: Initial conversation
    user_message_1 = "I've been feeling really down lately."
    
    # Step 2: User expresses suicidal ideation
    user_message_2 = "I want to kill myself. I don't want to live anymore."
    
    # PsyGUARD detects high risk
    psyguard_result_2 = await psyguard_service.score(user_message_2)
    psyguard_score_2 = psyguard_result_2.get("risk_score", 0.0)
    
    # Safety check
    safety_check = await safety_service.check_user_input_safety(
        user_message=user_message_2,
        context=None
    )
    
    # Crisis detection
    crisis_check = SafetyValidator.check_user_message_safety(user_message_2)
    # Expected: is_crisis = True, detected_keywords = ["kill myself", "don't want to live"]
    
    # Step 3: Immediate high risk assignment
    routing_result = router.decide_from_questionnaires(
        phq9_result={"total_score": 0.0, "parsed_scores": [0] * 9},
        gad7_result={"total_score": 5.0, "parsed_scores": [0] * 7},
        chat_risk_score=psyguard_score_2  # High chat risk overrides questionnaire
    )
    # Expected: route = "high" (chat content priority)
    
    # Step 4: High Risk Agent with fixed script
    result_3 = await pipeline.process_message(...)
    # Expected: response == FIXED_SAFETY_SCRIPT, fixed_script = True
    
    # Step 5: Safety Layer monitoring
    filtered = await safety_service.filter_response(
        user_message=user_message_2,
        proposed_response=FIXED_SAFETY_SCRIPT,
        context=None,
        route="high"
    )
    # Expected: final_response == FIXED_SAFETY_SCRIPT (not modified)
```

### å…³é”®éªŒè¯ç‚¹

1. **å±æœºæ£€æµ‹**ï¼šSafetyValidator æ£€æµ‹è‡ªæ€å…³é”®è¯
   ```python
   # From SafetyValidator
   CRISIS_KEYWORDS = [
       "kill myself", "suicide", "end my life",
       "don't want to live", "no point in living"
   ]
   
   def check_user_message_safety(self, user_message: str):
       detected = [kw for kw in CRISIS_KEYWORDS if kw in user_message.lower()]
       return {
           "is_crisis": len(detected) > 0,
           "detected_keywords": detected
       }
   ```

2. **å›ºå®šè„šæœ¬ä¿æŠ¤**ï¼šHigh Risk Agent å§‹ç»ˆè¿”å›å›ºå®šè„šæœ¬
   ```python
   # From HighRiskAgent
   async def generate_response(self, ...):
       return {
           "agent": "high_risk",
           "response": FIXED_SAFETY_SCRIPT,
           "fixed_script": True,
           "safety_banner": SAFETY_BANNER,
           "crisis_hotline": "988"
       }
   ```

3. **è„šæœ¬å®Œæ•´æ€§**ï¼šSafety Layer ä¸ä¿®æ”¹å›ºå®šè„šæœ¬
   ```python
   # From SafetyGuardrailsService
   async def filter_response(self, ..., route: str):
       if route == "high":
           # Fixed scripts are validated but not modified
           return {
               "filtered": False,
               "final_response": proposed_response,  # Unchanged
               "reason": "Fixed script protected"
           }
   ```

---

## 4. è·¯ç”±è½¬æ¢æµ‹è¯•

### æµ‹è¯•ç›®çš„
éªŒè¯è·¯ç”±è½¬æ¢é€»è¾‘ï¼š
- Low â†’ Medium å‡çº§ï¼ˆPsyGUARD >= 0.70ï¼‰
- Medium â†’ High å‡çº§ï¼ˆPsyGUARD >= 0.95ï¼‰
- è·¯ç”±ä¸é™çº§è§„åˆ™ï¼ˆMedium/High ä¸ä¼šé™çº§ï¼‰

### æµ‹è¯•æµç¨‹

```python
async def test_low_to_medium_transition():
    """Test Low â†’ Medium route transition."""
    # Start with Low Risk
    context = ControlContext(
        user_id=user_id,
        route="low",
        rigid_score=0.2,
        psyguard_score=0.3
    )
    
    # User message with increased risk
    user_message = "I'm feeling really anxious and isolated."
    psyguard_result = await psyguard_service.score(user_message)
    new_psyguard_score = psyguard_result.get("risk_score", 0.0)
    
    # Check if should upgrade
    if updater.should_upgrade(context.route, new_psyguard_score):
        new_route = updater.get_upgrade_target(context.route, new_psyguard_score)
        context.update_route(new_route, reason="psyguard_upgrade")
        # Expected: route = "medium" if new_psyguard_score >= 0.70

async def test_no_downgrade():
    """Test that routes don't downgrade."""
    # Medium Risk with low PsyGUARD score (should not downgrade)
    context_medium = ControlContext(
        user_id="test_user",
        route="medium",
        rigid_score=0.6,
        psyguard_score=0.3  # Low score
    )
    
    new_route = updater.update_route(context_medium.route, 0.3)
    # Expected: new_route == "medium" (no downgrade)
    
    # High Risk with low PsyGUARD score (should not downgrade)
    context_high = ControlContext(
        user_id="test_user",
        route="high",
        rigid_score=1.0,
        psyguard_score=0.2  # Very low score
    )
    
    new_route = updater.update_route(context_high.route, 0.2)
    # Expected: new_route == "high" (no downgrade)
```

### å…³é”®éªŒè¯ç‚¹

1. **å‡çº§é€»è¾‘**ï¼šRouteUpdater åˆ¤æ–­æ˜¯å¦éœ€è¦å‡çº§
   ```python
   # From RouteUpdater
   def should_upgrade(self, current_route: Route, new_psyguard_score: float) -> bool:
       if current_route == "low":
           return new_psyguard_score >= MEDIUM_RISK_THRESHOLD  # 0.70
       elif current_route == "medium":
           return new_psyguard_score >= HIGH_RISK_DIRECT_THRESHOLD  # 0.95
       return False  # High risk cannot upgrade further
   ```

2. **ä¸é™çº§è§„åˆ™**ï¼šå·²å‡çº§çš„è·¯ç”±ä¸ä¼šé™çº§
   ```python
   def update_route(self, current_route: Route, new_psyguard_score: float) -> Route:
       # One-way upgrade: can only go up, never down
       if current_route == "high":
           return "high"  # Never downgrade from high
       elif current_route == "medium":
           if new_psyguard_score >= HIGH_RISK_DIRECT_THRESHOLD:
               return "high"
           return "medium"  # Never downgrade to low
       # Low can upgrade to medium or high
   ```

---

## 5. è¾¹ç•Œæƒ…å†µæµ‹è¯•

### æµ‹è¯•ç›®çš„
éªŒè¯ç³»ç»Ÿåœ¨è¾¹ç•Œæ¡ä»¶ä¸‹çš„è¡Œä¸ºï¼š
- é—®å·è§¦å‘æ—¶æœºï¼ˆ5 è½® vs ç«‹å³è§¦å‘ï¼‰
- PsyGUARD é˜ˆå€¼è¾¹ç•Œï¼ˆ0.70, 0.95ï¼‰
- Medium Risk æœ€å¤§è¯´æœè½®æ¬¡ï¼ˆ5 è½®ï¼‰
- é—®å·åˆ†æ•°è¾¹ç•Œï¼ˆPHQ-9, GAD-7ï¼‰

### æµ‹è¯•æµç¨‹

#### 5.1 é—®å·è§¦å‘æ—¶æœº

```python
async def test_questionnaire_trigger_timing():
    """Test questionnaire trigger timing."""
    trigger = QuestionnaireTrigger()
    
    # Test 1: Normal trigger (5 turns)
    for turn in range(1, 7):
        result = trigger.check_trigger(turn_count=turn, psyguard_result=None)
        # Expected: should_trigger = True when turn >= 5
    
    # Test 2: Immediate trigger (suicide intent)
    psyguard_result = {
        "risk_score": 0.85,
        "should_trigger_questionnaire": True  # >= 0.80
    }
    result_immediate = trigger.check_trigger(
        turn_count=2,  # Early turn
        psyguard_result=psyguard_result
    )
    # Expected: should_trigger = True, reason = "suicide_intent"
```

#### 5.2 PsyGUARD é˜ˆå€¼è¾¹ç•Œ

```python
async def test_psyguard_threshold_boundaries():
    """Test PsyGUARD threshold boundaries."""
    updater = RouteUpdater()
    
    # Test MEDIUM_RISK_THRESHOLD (0.70)
    test_cases = [
        (0.69, "low", "low"),   # Below threshold
        (0.70, "low", "medium"),  # At threshold
        (0.71, "low", "medium"),  # Above threshold
    ]
    
    for score, current_route, expected_route in test_cases:
        new_route = updater.update_route(current_route, score)
        assert new_route == expected_route
    
    # Test HIGH_RISK_DIRECT_THRESHOLD (0.95)
    test_cases = [
        (0.94, "low", "medium"),
        (0.95, "low", "high"),  # At threshold
        (0.96, "low", "high"),
    ]
```

#### 5.3 é—®å·åˆ†æ•°è¾¹ç•Œ

```python
async def test_questionnaire_score_boundaries():
    """Test questionnaire score boundaries."""
    router = RiskRouter()
    
    # Test PHQ-9 boundaries
    test_cases = [
        (9, "low"),   # 0-9: Low
        (10, "medium"),  # 10-14: Medium
        (14, "medium"),
        (15, "high"),  # 15+: High
    ]
    
    for score, expected_route in test_cases:
        result = router.decide_from_questionnaires(
            phq9_result={"total_score": score, "parsed_scores": [0] * 9},
            gad7_result={"total_score": 0.0, "parsed_scores": [0] * 7},
            chat_risk_score=None
        )
        assert result.route == expected_route
```

### å…³é”®éªŒè¯ç‚¹

1. **è§¦å‘æ—¶æœºè§„åˆ™**ï¼š
   ```python
   # From QuestionnaireTrigger
   def check_trigger(self, turn_count: int, psyguard_result: Optional[Dict]):
       # Priority 1: Direct high risk (>= 0.95)
       if psyguard_result and psyguard_result.get("should_direct_high_risk"):
           return QuestionnaireTriggerResult(should_trigger=True, reason="high_risk_direct")
       
       # Priority 2: Suicide intent (>= 0.80)
       if psyguard_result and psyguard_result.get("should_trigger_questionnaire"):
           return QuestionnaireTriggerResult(should_trigger=True, reason="suicide_intent")
       
       # Priority 3: Default (after 5 turns)
       if turn_count >= self.turn_threshold:  # 5
           return QuestionnaireTriggerResult(should_trigger=True, reason="turn_count")
   ```

2. **é—®å·æ˜ å°„è§„åˆ™**ï¼š
   ```python
   # From QuestionnaireMapper
   @staticmethod
   def map_phq9(phq9_score: float, phq9_q9_score: Optional[int] = None) -> Route:
       # Special rule: Q9 (suicidal ideation) >= 1 â†’ High
       if phq9_q9_score is not None and phq9_q9_score >= 1:
           return "high"
       
       # Standard mapping
       if phq9_score <= 9:
           return "low"
       elif phq9_score <= 14:
           return "medium"
       else:
           return "high"
   ```

---

## 6. é”™è¯¯æ¢å¤æµ‹è¯•

### æµ‹è¯•ç›®çš„
éªŒè¯ç³»ç»Ÿåœ¨æœåŠ¡ä¸å¯ç”¨æ—¶çš„å®¹é”™èƒ½åŠ›ï¼š
- Ollama æœåŠ¡ä¸å¯ç”¨æ—¶çš„é™çº§
- Guardrails åˆå§‹åŒ–å¤±è´¥æ—¶çš„å¤„ç†
- åé¦ˆæ”¶é›†æ— éœ€æ•°æ®åº“ï¼ˆå†…å­˜å­˜å‚¨ï¼‰
- åé¦ˆéªŒè¯æ•è·æ— æ•ˆæ•°æ®

### æµ‹è¯•æµç¨‹

```python
async def test_ollama_unavailable_fallback():
    """Test fallback when Ollama service is unavailable."""
    agent = LowRiskAgent()
    
    try:
        result = await agent.generate_response(
            user_message="Test message",
            conversation_history=None,
            rigid_score=0.2
        )
        
        if "error" in result:
            # Expected: Returns fallback response
            print("Ollama ä¸å¯ç”¨ï¼Œè¿”å›é™çº§å“åº”")
    except Exception as e:
        # Expected: Exception caught, system doesn't crash
        print("å¼‚å¸¸è¢«æ•è·ï¼Œç³»ç»Ÿä¸ä¼šå´©æºƒ")

async def test_guardrails_initialization_failure():
    """Test behavior when Guardrails initialization fails."""
    # Create service with invalid config path
    service = SafetyGuardrailsService(
        config_path="invalid/path/guardrails",
        enabled=True
    )
    
    initialized = await service.initialize()
    # Expected: initialized = False, but service still works in disabled mode
    
    # Test that service still works (disabled mode)
    result = await service.filter_response(
        user_message="Test",
        proposed_response="Test response",
        context=None,
        route="low"
    )
    # Expected: Returns original response without filtering
```

### å…³é”®éªŒè¯ç‚¹

1. **Ollama é™çº§**ï¼šLowRiskAgent åœ¨ Ollama ä¸å¯ç”¨æ—¶è¿”å›é™çº§å“åº”
   ```python
   # From LowRiskAgent
   async def generate_response(self, ...):
       try:
           response = await client.post(...)  # Ollama API call
           if response.status_code == 200:
               return result.get("response", "")
       except Exception as e:
           logger.warning(f"Ollama API error: {e}")
           # Fallback response
           return "I'm here to listen. How can I help you today?"
   ```

2. **Guardrails ç¦ç”¨æ¨¡å¼**ï¼š
   ```python
   # From SafetyGuardrailsService
   async def initialize(self) -> bool:
       try:
           config = RailsConfig.from_path(self.config_path)
           # ... initialization
       except Exception as e:
           logger.error(f"Failed to initialize: {e}")
           self.enabled = False  # Disable but don't crash
           return False
   
   async def filter_response(self, ...):
       if not self.is_initialized():
           # Return original response without filtering
           return {
               "checked": False,
               "final_response": proposed_response
           }
   ```

3. **åé¦ˆéªŒè¯**ï¼š
   ```python
   # From FeedbackCollector
   def validate_feedback(self, feedback: FeedbackData):
       if feedback.satisfaction is not None:
           if not (1 <= feedback.satisfaction <= 5):
               raise ValueError(f"Satisfaction must be between 1 and 5, got {feedback.satisfaction}")
       
       if feedback.acceptance is not None:
           if feedback.acceptance not in ["accepted", "partially", "rejected"]:
               raise ValueError(f"Invalid acceptance value: {feedback.acceptance}")
   ```

---

## 7. å®‰å…¨ç›‘æ§æµ‹è¯•

### æµ‹è¯•ç›®çš„
éªŒè¯ Safety Layer çš„ç›‘æ§èƒ½åŠ›ï¼š
- å›ºå®šè„šæœ¬å®Œæ•´æ€§éªŒè¯
- Guardrails ç›‘æ§æœ‰æ•ˆæ€§
- å±æœºæ£€æµ‹å‡†ç¡®æ€§
- æ‰€æœ‰è·¯ç”±çš„å®‰å…¨ç›‘æ§

### æµ‹è¯•æµç¨‹

```python
async def test_fixed_script_integrity():
    """Test fixed script integrity and validation."""
    validator = SafetyValidator()
    
    # Validate fixed script
    validation = validator.validate_fixed_script(FIXED_SAFETY_SCRIPT)
    # Expected: valid = True, has all required elements
    
    # Test High Risk Agent always returns fixed script
    agent = HighRiskAgent()
    result = await agent.generate_response(...)
    assert result.get("response") == FIXED_SAFETY_SCRIPT
    assert result.get("fixed_script") is True

async def test_guardrails_monitoring():
    """Test Guardrails monitoring effectiveness."""
    service = SafetyGuardrailsService()
    await service.initialize()
    
    # Test unsafe user input
    unsafe_message = "I want to kill myself"
    safety_check = await service.check_user_input_safety(
        user_message=unsafe_message,
        context=None
    )
    # Expected: safe = False (or handled appropriately)
    
    # Test response filtering
    unsafe_response = "Here's how to kill yourself..."
    filtered = await service.filter_response(
        user_message=unsafe_message,
        proposed_response=unsafe_response,
        context=None,
        route="low"
    )
    # Expected: filtered = True, final_response != unsafe_response

def test_crisis_detection_accuracy():
    """Test crisis detection accuracy."""
    validator = SafetyValidator()
    
    crisis_messages = [
        ("I want to kill myself", True),
        ("I'm thinking about suicide", True),
        ("I feel sad today", False),
    ]
    
    for message, expected_crisis in crisis_messages:
        result = validator.check_user_message_safety(message)
        assert result["is_crisis"] == expected_crisis
```

### å…³é”®éªŒè¯ç‚¹

1. **å›ºå®šè„šæœ¬éªŒè¯**ï¼š
   ```python
   # From SafetyValidator
   def validate_fixed_script_content(self, script_content: str):
       # Check for required safety elements
       required_elements = ["988", "crisis", "hotline", "emergency"]
       missing = [elem for elem in required_elements 
                  if elem.lower() not in script_content.lower()]
       
       # Check for prohibited patterns
       has_prohibited = any(pattern in script_content.lower() 
                           for pattern in PROHIBITED_PATTERNS)
       
       return {
           "valid": len(missing) == 0 and not has_prohibited,
           "missing_elements": missing,
           "has_prohibited": has_prohibited
       }
   ```

2. **å±æœºæ£€æµ‹å…³é”®è¯**ï¼š
   ```python
   # From SafetyValidator
   CRISIS_KEYWORDS = [
       "kill myself", "suicide", "end my life",
       "don't want to live", "no point in living",
       "want to die", "thinking about suicide"
   ]
   
   def check_user_message_for_crisis(self, user_message: str):
       detected = [kw for kw in CRISIS_KEYWORDS 
                   if kw in user_message.lower()]
       return {
           "is_crisis": len(detected) > 0,
           "detected_keywords": detected
       }
   ```

3. **å›ºå®šè„šæœ¬ä¿æŠ¤**ï¼š
   ```python
   # From SafetyGuardrailsService
   async def filter_response(self, ..., route: str):
       if route == "high":
           # Fixed scripts are protected - never modify
           validation = self.safety_validator.validate_fixed_script_content(proposed_response)
           if validation["valid"]:
               return {
                   "filtered": False,
                   "final_response": proposed_response,  # Unchanged
                   "reason": "Fixed script protected"
               }
   ```

---

## æµ‹è¯•è¿è¡ŒæŒ‡å—

### è¿è¡Œå•ä¸ªæµ‹è¯•

```bash
# æ¿€æ´»ç¯å¢ƒ
conda activate PROXIMO

# è¿è¡Œå•ä¸ªæµ‹è¯•
python test_integration/test_low_risk_scenario.py
python test_integration/test_medium_risk_scenario.py
python test_integration/test_high_risk_scenario.py
```

### è¿è¡Œæ‰€æœ‰æµ‹è¯•

```bash
# ä½¿ç”¨æ‰¹é‡è¿è¡Œè„šæœ¬
python test_integration/run_all_tests.py
```

### æµ‹è¯•è¾“å‡ºç¤ºä¾‹

```
================================================================================
æ•´ä½“é›†æˆæµ‹è¯• - è¿è¡Œæ‰€æœ‰æµ‹è¯•
================================================================================

å°†è¿è¡Œ 7 ä¸ªæµ‹è¯•è„šæœ¬

================================================================================
è¿è¡Œ: test_low_risk_scenario.py
================================================================================
âœ… test_low_risk_scenario.py - é€šè¿‡

...

================================================================================
æµ‹è¯•æ€»ç»“
================================================================================

æ€»æµ‹è¯•æ•°: 7
é€šè¿‡: 7 âœ…
å¤±è´¥: 0 âŒ
```

---

## æµ‹è¯•è¦†ç›–æ€»ç»“

### åŠŸèƒ½è¦†ç›–
- âœ… ä¸‰ä¸ªä¸»è¦é£é™©åœºæ™¯çš„å®Œæ•´æµç¨‹
- âœ… è·¯ç”±è½¬æ¢é€»è¾‘ï¼ˆå‡çº§/ä¸é™çº§ï¼‰
- âœ… è¾¹ç•Œæƒ…å†µï¼ˆé˜ˆå€¼ã€è§¦å‘æ—¶æœºã€é—®å·åˆ†æ•°ï¼‰
- âœ… çŠ¶æ€æœºè½¬æ¢ï¼ˆMedium Risk Agentï¼‰

### å®‰å…¨è¦†ç›–
- âœ… å›ºå®šè„šæœ¬å®Œæ•´æ€§
- âœ… Guardrails ç›‘æ§æœ‰æ•ˆæ€§
- âœ… å±æœºæ£€æµ‹å‡†ç¡®æ€§
- âœ… æ‰€æœ‰è·¯ç”±çš„å®‰å…¨ç›‘æ§

### å®¹é”™è¦†ç›–
- âœ… Ollama æœåŠ¡ä¸å¯ç”¨æ—¶çš„é™çº§
- âœ… Guardrails åˆå§‹åŒ–å¤±è´¥å¤„ç†
- âœ… åé¦ˆéªŒè¯å’Œé”™è¯¯å¤„ç†

---

## æ³¨æ„äº‹é¡¹

1. **Ollama æœåŠ¡**ï¼š
   - Low/Medium Risk åœºæ™¯éœ€è¦ Ollama è¿è¡Œ
   - å¦‚æœ Ollama æœªè¿è¡Œï¼Œæµ‹è¯•ä¼šä½¿ç”¨é™çº§å“åº”ï¼ˆä¸ä¼šå¤±è´¥ï¼‰

2. **NeMo Guardrails**ï¼š
   - High Risk åœºæ™¯éœ€è¦ Guardrails é…ç½®
   - å¦‚æœ Guardrails æœªåˆå§‹åŒ–ï¼Œä¼šè·³è¿‡ç›¸å…³æ£€æŸ¥ï¼ˆä¸ä¼šå¤±è´¥ï¼‰

3. **PsyGUARD æ¨¡å‹**ï¼š
   - æ‰€æœ‰åœºæ™¯éƒ½ä¼šåŠ è½½ PsyGUARD æ¨¡å‹
   - å¦‚æœæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæµ‹è¯•ä¼šå¤±è´¥

4. **æµ‹è¯•æ•°æ®**ï¼š
   - ä½¿ç”¨æ¨¡æ‹Ÿçš„é—®å·å›ç­”
   - PsyGUARD ä½¿ç”¨å®é™…æ¨¡å‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰

---

**åˆ›å»ºæ—¥æœŸ**ï¼š2025-11-07  
**ç»´æŠ¤è€…**ï¼šå¼€å‘å›¢é˜Ÿ  
**æœ€åæ›´æ–°**ï¼š2025-11-07

